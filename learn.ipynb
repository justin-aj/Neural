{
 "cells": [
  {
   "cell_type": "raw",
   "id": "da328e68-d94b-4afb-8cce-646bee63da37",
   "metadata": {},
   "source": [
    "Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "461cfb71-555a-4f9d-9127-93c56ea7d851",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5bfe702e-6af5-4cb2-a820-3f7d2e153e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope: [0.78571429], Intercept: 1.5714285714285712, Predicted: [3.14285714]\n",
      "Score: 0.7346938775510206\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[1], [2], [3], [4]])\n",
    "y = np.array([2, 4, 5, 4])\n",
    "model = LinearRegression()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"Slope: {model.coef_}, Intercept: {model.intercept_}, Predicted: {y_pred}\")\n",
    "score = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Score: {score}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "20b87fc9-7325-44dd-bc3a-9696e80973e0",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27541b4a-ca93-43dd-b581-c7dd75567c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "LogLoss: 2.220446049250313e-16\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, log_loss, precision_score, recall_score, f1_score\n",
    "X = [[1], [2], [3], [4]]\n",
    "y = [0, 0, 1, 1]\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X)\n",
    "print(\"Accuracy:\", accuracy_score(y, y_pred))\n",
    "# TP + TN/Total\n",
    "print(\"LogLoss:\", log_loss(y, y_pred))\n",
    "# -1/N sum(yi * log(pi) + (1-yi) * log(1-pi))\n",
    "print(\"Precision:\", precision_score(y, y_pred))\n",
    "# TP/TP + FP\n",
    "print(\"Recall:\", recall_score(y, y_pred))\n",
    "# TP/TP + FN\n",
    "print(\"F1Score:\", f1_score(y, y_pred))\n",
    "# 2 * P . R / P + R"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f33e6c95-f6f7-4127-aea9-2bf0d0cc4c27",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df808010-26ed-4abf-bd5a-7ccb3ab2e1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\n",
    "y = np.array([0, 0, 1, 1])\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1cb744eb-fd6c-4385-8468-db9ecf7bc2fc",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da067c43-966c-4ff3-9f16-22780399ac15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\n",
    "y = np.array([0, 0, 1, 1])\n",
    "model = SVC(kernel='rbf')\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d79cee5b-91cf-4247-869f-59235f5899bc",
   "metadata": {},
   "source": [
    "RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f3571ab-eafb-4305-b766-56c20f5e4d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\n",
    "y = np.array([0, 0, 1, 1])\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=5, criterion='gini')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "20628a0f-4d06-4041-a44e-817b5c17f0a0",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0bd7f190-02e2-4fea-b96d-4aeda7c1322c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n",
      "Confusion Matrix:\n",
      " [[2 0]\n",
      " [2 0]]\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "X = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\n",
    "y = np.array([0, 0, 1, 1])\n",
    "\n",
    "# Train model\n",
    "model = xgb.XGBClassifier(n_estimators=100, max_depth=3, learning_rate=0.1, random_state=42)\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y, y_pred))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4c6a95da-4659-441b-a480-570087664bde",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c6c5c897-e271-4cd7-8c32-9a509795b0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75\n",
      "Confusion Matrix:\n",
      " [[2 0]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "X = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\n",
    "y = np.array([0, 0, 1, 1])\n",
    "\n",
    "# Train model\n",
    "model = KNeighborsClassifier(n_neighbors=2)\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y, y_pred))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ad1961f3-1cdc-4c2e-9d7f-94997ca9773c",
   "metadata": {},
   "source": [
    "GradientBoosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3f4dc6b8-2b36-404d-9b42-a3f650e829b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      " [[2 0]\n",
      " [0 2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "X = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\n",
    "y = np.array([0, 0, 1, 1])\n",
    "\n",
    "# Train model\n",
    "model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3)\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y, y_pred))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a5b6540d-f254-4e45-83de-2a991133e41d",
   "metadata": {},
   "source": [
    "LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "20ee71cb-3be7-45fb-8b5a-6ac05c61e2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original feature shape: (4, 2)\n",
      "Transformed feature shape: (4, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Apply LDA for feature extraction (reduce to 2 features)\n",
    "lda = LinearDiscriminantAnalysis(n_components=1)\n",
    "X_lda = lda.fit_transform(X, y)\n",
    "\n",
    "print(\"Original feature shape:\", X.shape)\n",
    "print(\"Transformed feature shape:\", X_lda.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0f6406b9-7a62-4e11-9f63-8abb90112c7e",
   "metadata": {},
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0f64bd71-2f2a-4f2b-8cfa-711f4526f511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original feature shape: (4, 2)\n",
      "Transformed feature shape: (4, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Apply LDA for feature extraction (reduce to 2 features)\n",
    "lda = PCA(n_components=1)\n",
    "X_lda = lda.fit_transform(X, y)\n",
    "\n",
    "print(\"Original feature shape:\", X.shape)\n",
    "print(\"Transformed feature shape:\", X_lda.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d2784e49-ca3d-4d80-b166-907a5d627dba",
   "metadata": {},
   "source": [
    "L1 Regression (Lasso Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7c5503c8-5003-45c9-9368-d0586c1eb57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.5829999999999996\n",
      "Coefficients: [0.62] Intercept: 2.2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([[1], [2], [3], [4]])\n",
    "y = np.array([2, 4, 5, 4])\n",
    "\n",
    "model = Lasso(alpha=0.1)  # Alpha controls sparsity\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y, y_pred))\n",
    "print(\"Coefficients:\", model.coef_, \"Intercept:\", model.intercept_)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "909b218c-9437-4d1d-8acf-54f072f4c9b5",
   "metadata": {},
   "source": [
    "L2 Regression (Ridge Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c126794c-2a63-4454-942a-f9b548b4ec8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.5920138888888891\n",
      "Coefficients: [0.58333333] Intercept: 2.291666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([[1], [2], [3], [4]])\n",
    "y = np.array([2, 4, 5, 4])\n",
    "\n",
    "model = Ridge(alpha=1.0)  # Alpha is the regularization strength\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y, y_pred))\n",
    "print(\"Coefficients:\", model.coef_, \"Intercept:\", model.intercept_)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ccce4314-fa08-4fca-8960-d596258da550",
   "metadata": {},
   "source": [
    "ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3728b9dd-4f99-430a-8693-7a974e7b35a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.5803439349112428\n",
      "Coefficients: [0.63461538] Intercept: 2.1634615384615383\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([[1], [2], [3], [4]])\n",
    "y = np.array([2, 4, 5, 4])\n",
    "\n",
    "model = ElasticNet(alpha=0.1, l1_ratio=0.5)  # Alpha is the regularization strength\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y, y_pred))\n",
    "print(\"Coefficients:\", model.coef_, \"Intercept:\", model.intercept_)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "85e21d97-a7ae-47a3-8d57-7535d8ad5d02",
   "metadata": {},
   "source": [
    "RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bba6ee7a-9b6c-4688-94c7-513d8e1701a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha for Ridge: 1.0\n",
      "Test Error (MSE) for Ridge: 0.20395421436004216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajinf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:2375: FutureWarning: 'store_cv_values' is deprecated in version 1.5 and will be removed in 1.7. Use 'store_cv_results' instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "alphas = [0.1, 1.0, 10.0, 100.0]\n",
    "\n",
    "model = RidgeCV(alphas=alphas, store_cv_values=True)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "test_error = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Best alpha for Ridge: {model.alpha_}\")\n",
    "print(f\"Test Error (MSE) for Ridge: {test_error}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d27081fe-966c-4d79-b425-3f25d7f5a17c",
   "metadata": {},
   "source": [
    "LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dc028f65-2bfb-48b1-ac53-9ee22693ea97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha for Lasso: 0.1\n",
      "Test Error (MSE) for Lasso: 0.22224489795918376\n",
      "Number of non-zero coefficients: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajinf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "alphas = [0.1, 1.0, 10.0, 100.0]\n",
    "\n",
    "model = LassoCV(alphas=alphas, cv=2)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "test_error = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "non_zero_coefs = sum(model.coef_ != 0)\n",
    "\n",
    "print(f\"Best alpha for Lasso: {model.alpha_}\")\n",
    "print(f\"Test Error (MSE) for Lasso: {test_error}\")\n",
    "print(f\"Number of non-zero coefficients: {non_zero_coefs}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aedd00a8-8cb1-4a06-b458-bb659058f3f7",
   "metadata": {},
   "source": [
    "Simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b56cbf59-0eef-4a2d-b412-827a9341bd48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x13fa61ec450>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "seed = 1234\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e4ba10b0-b76f-4bd5-84d1-a3a2de15fa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.load(r'C:\\Users\\ajinf\\Downloads\\MNIST\\MNIST\\processed\\training.pt', weights_only=True)\n",
    "test_data = torch.load(r'C:\\Users\\ajinf\\Downloads\\MNIST\\MNIST\\processed\\test.pt', weights_only=True)\n",
    "\n",
    "train_images, train_labels = train_data\n",
    "test_images, test_labels = test_data\n",
    "train_images = train_images.float().unsqueeze(1) / 255.0 \n",
    "test_images = test_images.float().unsqueeze(1) / 255.0 \n",
    "\n",
    "train_dataset = TensorDataset(train_images, train_labels)\n",
    "test_dataset = TensorDataset(test_images, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ed8e64ae-befe-4b8f-94a8-b6f109a77920",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "36bc7a84-2d9a-4300-82d7-6d60e385f2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Small(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Small, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=10, out_channels=20, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.batchnn = nn.BatchNorm2d(num_features=20)\n",
    "        self.fc1 = nn.Linear(320, 10)\n",
    "        self.pooling = nn.MaxPool2d(kernel_size=2, padding=0, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv2(self.conv1(x))\n",
    "        x = self.relu(x)\n",
    "        x = self.pooling(x)\n",
    "        x = self.batchnn(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1fb5a6e6-df1e-4d7a-965d-9e3435d1372e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_Small()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8e68861c-142e-4ed0-a52a-872882272957",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (32x3920 and 320x10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[105], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img, label \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m      5\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m----> 6\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, label)\n\u001b[0;32m      8\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[103], line 17\u001b[0m, in \u001b[0;36mCNN_Small.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     15\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatchnn(x)\n\u001b[0;32m     16\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x3920 and 320x10)"
     ]
    }
   ],
   "source": [
    "epoch = 1\n",
    "for i in range(epoch):\n",
    "    model.train()\n",
    "    for img, label in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(img)\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    for img, label in test_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(img)\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cc0751-519c-47b2-b601-c9450f917272",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
